{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urdu Digits Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6606 images belonging to 10 classes.\n",
      "Found 1414 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading and Pre-processing the dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Pre-processing the dataset\n",
    "train_datagen = ImageDataGenerator(rescale=None,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Loading the dataset\n",
    "training_set = train_datagen.flow_from_directory(\"digits_train_set\",target_size=(28,28),batch_size=32,class_mode=\"categorical\",color_mode=\"grayscale\")\n",
    "testing_set  = test_datagen.flow_from_directory(\"digits_test_set\",target_size=(28,28),batch_size=32,class_mode=\"categorical\",color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing the CNN Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation=\"relu\",input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN Model\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.9873 - accuracy: 0.6508 - val_loss: 3.6063 - val_accuracy: 0.1013\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.7422 - accuracy: 0.7360 - val_loss: 4.5549 - val_accuracy: 0.1112\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 0.7024 - accuracy: 0.7586 - val_loss: 4.7353 - val_accuracy: 0.1037\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 7s 65ms/step - loss: 0.6085 - accuracy: 0.7835 - val_loss: 4.2667 - val_accuracy: 0.0962\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 7s 65ms/step - loss: 0.5875 - accuracy: 0.7950 - val_loss: 4.8129 - val_accuracy: 0.1112\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5775 - accuracy: 0.7944Restoring model weights from the end of the best epoch: 1.\n",
      "100/100 [==============================] - 7s 65ms/step - loss: 0.5775 - accuracy: 0.7944 - val_loss: 4.4717 - val_accuracy: 0.0962\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4a70ab5b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the CNN Model\n",
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=5,restore_best_weights=True,verbose = 1)\n",
    "model.fit(training_set,steps_per_epoch=100,epochs=10,validation_data=testing_set,validation_steps=25,callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "digits_test_set\\0\\0 (1).jpg 0\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "digits_test_set\\0\\0 (10).jpg 0\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "digits_test_set\\0\\0 (100).jpg 0\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "digits_test_set\\0\\0 (101).jpg 6\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "digits_test_set\\0\\0 (102).jpg 6\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "digits_test_set\\1\\1 (1).jpg 1\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "digits_test_set\\1\\1 (10).jpg 0\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "digits_test_set\\1\\1 (100).jpg 1\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "digits_test_set\\1\\1 (101).jpg 1\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "digits_test_set\\1\\1 (102).jpg 1\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "digits_test_set\\2\\2 (1).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\2\\2 (10).jpg 6\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\2\\2 (100).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\2\\2 (101).jpg 2\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\2\\2 (102).jpg 4\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\3\\3 (1).jpg 3\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "digits_test_set\\3\\3 (10).jpg 3\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "digits_test_set\\3\\3 (100).jpg 3\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "digits_test_set\\3\\3 (101).jpg 4\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "digits_test_set\\3\\3 (102).jpg 4\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "digits_test_set\\4\\4 (1).jpg 4\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "digits_test_set\\4\\4 (10).jpg 4\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "digits_test_set\\4\\4 (100).jpg 8\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\4\\4 (101).jpg 4\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "digits_test_set\\4\\4 (102).jpg 4\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\5\\5 (1).jpg 5\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\5\\5 (10).jpg 5\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "digits_test_set\\5\\5 (100).jpg 5\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\5\\5 (101).jpg 5\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "digits_test_set\\5\\5 (102).jpg 5\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "digits_test_set\\6\\6 (1).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "digits_test_set\\6\\6 (10).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\6\\6 (100).jpg 5\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\6\\6 (101).jpg 6\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\6\\6 (102).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\7\\7 (1).jpg 7\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "digits_test_set\\7\\7 (10).jpg 7\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "digits_test_set\\7\\7 (100).jpg 7\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\7\\7 (101).jpg 7\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "digits_test_set\\7\\7 (102).jpg 7\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "digits_test_set\\8\\8 (1).jpg 8\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "digits_test_set\\8\\8 (10).jpg 8\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "digits_test_set\\8\\8 (100).jpg 8\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "digits_test_set\\8\\8 (101).jpg 8\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "digits_test_set\\8\\8 (102).jpg 8\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\9\\9 (1).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "digits_test_set\\9\\9 (10).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "digits_test_set\\9\\9 (100).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "digits_test_set\\9\\9 (101).jpg 9\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "digits_test_set\\9\\9 (102).jpg 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the CNN Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def classify(img_file):\n",
    "    imgs = img_file\n",
    "    img = tf.keras.preprocessing.image.load_img(imgs,target_size=(28,28),color_mode=\"grayscale\")\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    result = model.predict(img)\n",
    "    classes = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "    print(imgs,classes[result.argmax()])\n",
    "\n",
    "    \n",
    "import os\n",
    "path = \"digits_test_set\"\n",
    "files = []\n",
    "for r,d,f in os.walk(path):\n",
    "    for file in f[ :5]:\n",
    "        if \".jpg\" in file:\n",
    "            #print(files)\n",
    "            files.append(os.path.join(r,file))\n",
    "for f in files:\n",
    "    classify(f)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
